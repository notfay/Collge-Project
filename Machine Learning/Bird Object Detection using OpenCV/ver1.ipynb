{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\intel x  nvidia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\intel x  nvidia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-contrib-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10m.pt to 'yolov10m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32.1M/32.1M [00:15<00:00, 2.15MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 453.8ms\n",
      "Speed: 4.0ms preprocess, 453.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bed, 324.1ms\n",
      "Speed: 3.0ms preprocess, 324.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 322.1ms\n",
      "Speed: 2.0ms preprocess, 322.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 288.2ms\n",
      "Speed: 2.0ms preprocess, 288.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 348.6ms\n",
      "Speed: 2.0ms preprocess, 348.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 351.1ms\n",
      "Speed: 2.0ms preprocess, 351.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 350.1ms\n",
      "Speed: 2.0ms preprocess, 350.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 350.1ms\n",
      "Speed: 2.0ms preprocess, 350.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 307.2ms\n",
      "Speed: 2.0ms preprocess, 307.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 327.1ms\n",
      "Speed: 2.0ms preprocess, 327.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 285.3ms\n",
      "Speed: 2.0ms preprocess, 285.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 284.2ms\n",
      "Speed: 1.0ms preprocess, 284.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 283.2ms\n",
      "Speed: 2.0ms preprocess, 283.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 300.2ms\n",
      "Speed: 2.0ms preprocess, 300.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 295.2ms\n",
      "Speed: 2.0ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 289.2ms\n",
      "Speed: 1.0ms preprocess, 289.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 285.3ms\n",
      "Speed: 2.0ms preprocess, 285.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 290.2ms\n",
      "Speed: 2.0ms preprocess, 290.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 306.2ms\n",
      "Speed: 2.0ms preprocess, 306.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 285.2ms\n",
      "Speed: 2.0ms preprocess, 285.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 beds, 284.2ms\n",
      "Speed: 2.0ms preprocess, 284.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 295.2ms\n",
      "Speed: 2.0ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 322.1ms\n",
      "Speed: 2.0ms preprocess, 322.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 291.2ms\n",
      "Speed: 1.0ms preprocess, 291.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 287.2ms\n",
      "Speed: 2.0ms preprocess, 287.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 279.2ms\n",
      "Speed: 2.0ms preprocess, 279.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 293.2ms\n",
      "Speed: 2.0ms preprocess, 293.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 311.2ms\n",
      "Speed: 2.0ms preprocess, 311.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 290.2ms\n",
      "Speed: 2.0ms preprocess, 290.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 295.2ms\n",
      "Speed: 1.0ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 297.2ms\n",
      "Speed: 3.0ms preprocess, 297.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 309.2ms\n",
      "Speed: 1.0ms preprocess, 309.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 350.1ms\n",
      "Speed: 1.0ms preprocess, 350.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 292.2ms\n",
      "Speed: 1.0ms preprocess, 292.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 290.2ms\n",
      "Speed: 1.0ms preprocess, 290.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 306.2ms\n",
      "Speed: 2.0ms preprocess, 306.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 beds, 287.2ms\n",
      "Speed: 2.0ms preprocess, 287.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 1 remote, 290.8ms\n",
      "Speed: 2.0ms preprocess, 290.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 1 remote, 286.2ms\n",
      "Speed: 2.0ms preprocess, 286.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 307.2ms\n",
      "Speed: 2.0ms preprocess, 307.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 1 remote, 292.2ms\n",
      "Speed: 2.0ms preprocess, 292.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 beds, 1 remote, 277.3ms\n",
      "Speed: 2.0ms preprocess, 277.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bed, 1 remote, 285.7ms\n",
      "Speed: 1.0ms preprocess, 285.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 beds, 1 remote, 310.2ms\n",
      "Speed: 3.0ms preprocess, 310.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 296.2ms\n",
      "Speed: 2.0ms preprocess, 296.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 beds, 288.2ms\n",
      "Speed: 2.0ms preprocess, 288.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 303.7ms\n",
      "Speed: 2.0ms preprocess, 303.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 287.2ms\n",
      "Speed: 2.0ms preprocess, 287.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 beds, 392.9ms\n",
      "Speed: 2.0ms preprocess, 392.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 332.1ms\n",
      "Speed: 2.0ms preprocess, 332.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 307.2ms\n",
      "Speed: 1.0ms preprocess, 307.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 295.2ms\n",
      "Speed: 2.0ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 384.0ms\n",
      "Speed: 3.0ms preprocess, 384.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 324.1ms\n",
      "Speed: 1.0ms preprocess, 324.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 316.2ms\n",
      "Speed: 2.0ms preprocess, 316.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 335.1ms\n",
      "Speed: 1.0ms preprocess, 335.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     85\u001b[0m     detector \u001b[38;5;241m=\u001b[39m ObjectDetection()\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m, in \u001b[0;36mObjectDetection.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_video()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m---> 68\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ultralytics import YOLO  # YOLO for TensorFlow\n",
    "\n",
    "class ObjectDetection:\n",
    "    \"\"\"\n",
    "    Class implements YOLOv8 model using TensorFlow/Keras for video inference.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, out_file=\"abc.mp4\"):\n",
    "        \"\"\"\n",
    "        Initializes the class with output file.\n",
    "        :param out_file: A valid output file name.\n",
    "        \"\"\"\n",
    "        self.model = self.load_model()\n",
    "        self.out_file = out_file\n",
    "        self.class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "    def get_video(self):\n",
    "        \"\"\"\n",
    "        Get webcam video from the device.\n",
    "        :return: OpenCV video capture object.\n",
    "        \"\"\"\n",
    "        return cv2.VideoCapture(0)\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads YOLOv10 model from TensorFlow/Keras.\n",
    "        :return: Loaded YOLO model.\n",
    "        \"\"\"\n",
    "        model = YOLO('yolov10m.pt')  # Load YOLOv10n model (Resource friendly, good for Kill Joy Bot) -> use yolov10m for general purpose (resource heavy)\n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Takes a single frame as input and scores it using the YOLOv10 model.\n",
    "        :param frame: Input frame in numpy format.\n",
    "        :return: Labels and coordinates of objects detected.\n",
    "        \"\"\"\n",
    "        results = self.model.predict(frame)\n",
    "        predictions = results[0].boxes\n",
    "        labels = predictions.cls.numpy()  # Get labels\n",
    "        cord = predictions.xyxy.numpy()  # Get bounding box coordinates\n",
    "        return labels, cord\n",
    "\n",
    "    def plot_boxes(self, results, frame):\n",
    "        \"\"\"\n",
    "        Plots the bounding boxes and labels on the frame.\n",
    "        :param results: Labels and coordinates of objects detected.\n",
    "        :param frame: Input frame in numpy format.\n",
    "        :return: Frame with bounding boxes and labels.\n",
    "        \"\"\"\n",
    "        labels, cord = results\n",
    "        for label, box in zip(labels, cord):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            class_name = self.class_names[int(label)]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        return frame\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the object detection on the webcam video feed.\n",
    "        \"\"\"\n",
    "        cap = self.get_video()\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            results = self.score_frame(frame)\n",
    "            frame = self.plot_boxes(results, frame)\n",
    "\n",
    "            cv2.imshow('YOLOv8 Object Detection', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    detector = ObjectDetection()\n",
    "    detector.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
